{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ĐỒ ÁN MÔN HỌC MÁY HỌC\n",
    "## Phân tích và dự đoán chất lượng rượu vang (Wine Quality – UCI)\n",
    "\n",
    "**Dataset:** Wine Quality (UCI Machine Learning Repository)  \n",
    "**Link:** https://archive.ics.uci.edu/dataset/186/wine+quality\n",
    "\n",
    "---\n",
    "\n",
    "## Checklist bắt buộc\n",
    "### EDA\n",
    "- info/describe, missing\n",
    "- 11 histogram features\n",
    "- correlation heatmap\n",
    "- quality distribution + label distribution\n",
    "- nhận xét đặc trưng ảnh hưởng\n",
    "\n",
    "### Preprocessing\n",
    "- missing explicit (SimpleImputer)\n",
    "- outliers explicit (IQR clipping) leak-free\n",
    "- scaling Standard/MinMax\n",
    "- split test_size 0.1/0.2/0.3 loop\n",
    "- label: 0 (≤5), 1 (≥6)\n",
    "\n",
    "### Models\n",
    "- Logistic Regression, Decision Tree, LightGBM, XGBoost\n",
    "\n",
    "### Evaluation\n",
    "- Accuracy, Precision, Recall, F1\n",
    "- Confusion matrix\n",
    "- ROC curve + AUC\n",
    "- bảng so sánh mô hình\n",
    "\n",
    "### Feature importance\n",
    "- LGBM + XGBoost\n",
    "\n",
    "## Optional \n",
    "- Train  Red vs White\n",
    "- Regression (RMSE/MAE/R2)\n",
    "- Cross-validation mean±std\n",
    "- Tuning (RandomizedSearchCV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Import & cấu hình\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution_count": null,
    "outputs": []
   },
   "source": [
    "# (Tuỳ chọn nếu thiếu trên Colab)\n",
    "# !pip -q install lightgbm xgboost\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_curve, auc,\n",
    "    mean_squared_error, mean_absolute_error, r2_score\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZES = (0.1, 0.2, 0.3)       \n",
    "LABEL_THRESHOLD = 6                # label=1 nếu quality>=6\n",
    "SCALER_MODE = \"standard\"           # \"standard\" hoặc \"minmax\"\n",
    "CV_FOLDS = 5                       # optional: 5-fold \n",
    "IQR_FACTOR = 1.5                   # outlier clipping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) (Tuỳ chọn) Tải dataset tự động nếu chưa có file CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution_count": null,
    "outputs": []
   },
   "source": [
    "import os, urllib.request\n",
    "\n",
    "base = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/\"\n",
    "files = {\n",
    "    \"winequality-red.csv\": base + \"winequality-red.csv\",\n",
    "    \"winequality-white.csv\": base + \"winequality-white.csv\",\n",
    "}\n",
    "\n",
    "for fn, url in files.items():\n",
    "    if not os.path.exists(fn):\n",
    "        print(\"Downloading:\", fn)\n",
    "        urllib.request.urlretrieve(url, fn)\n",
    "\n",
    "print(\"Files present:\", [fn for fn in files if os.path.exists(fn)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Data Ingestion: đọc đỏ + trắng, concat, thêm wine_type\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution_count": null,
    "outputs": []
   },
   "source": [
    "RED_PATH = \"winequality-red.csv\"\n",
    "WHITE_PATH = \"winequality-white.csv\"\n",
    "sep = \";\"\n",
    "\n",
    "df_red = pd.read_csv(RED_PATH, sep=sep)\n",
    "df_white = pd.read_csv(WHITE_PATH, sep=sep)\n",
    "\n",
    "df_red[\"wine_type\"] = \"red\"\n",
    "df_white[\"wine_type\"] = \"white\"\n",
    "\n",
    "df = pd.concat([df_red, df_white], ignore_index=True)\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) EDA: info/describe + missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution_count": null,
    "outputs": []
   },
   "source": [
    "display(df.info())\n",
    "display(df.describe())\n",
    "\n",
    "missing = df.isna().sum().sort_values(ascending=False)\n",
    "display(missing[missing > 0])\n",
    "print(\"Total missing:\", int(missing.sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) EDA: phân bố quality + nhãn nhị phân (0:<=5, 1:>=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution_count": null,
    "outputs": []
   },
   "source": [
    "plt.figure()\n",
    "df[\"quality\"].hist(bins=20)\n",
    "plt.title(\"Distribution of quality\")\n",
    "plt.xlabel(\"quality\"); plt.ylabel(\"count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "df[\"label\"] = (df[\"quality\"] >= LABEL_THRESHOLD).astype(int)\n",
    "display(df[\"label\"].value_counts(normalize=True).rename(\"proportion\"))\n",
    "\n",
    "plt.figure()\n",
    "df[\"label\"].value_counts().sort_index().plot(kind=\"bar\")\n",
    "plt.title(\"Binary label distribution (0:<=5, 1:>=6)\")\n",
    "plt.xlabel(\"label\"); plt.ylabel(\"count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) EDA: Phân bố từng đặc trưng (11 histogram)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution_count": null,
    "outputs": []
   },
   "source": [
    "feature_cols = [c for c in df.columns if c not in [\"quality\",\"label\",\"wine_type\"]]\n",
    "\n",
    "cols = 4\n",
    "rows = int(np.ceil(len(feature_cols)/cols))\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    plt.subplot(rows, cols, i)\n",
    "    plt.hist(df[col].dropna(), bins=30)\n",
    "    plt.title(col, fontsize=10)\n",
    "    plt.xlabel(col, fontsize=8)\n",
    "    plt.ylabel(\"count\", fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) EDA: Correlation heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution_count": null,
    "outputs": []
   },
   "source": [
    "num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "corr = df[num_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(corr, aspect=\"auto\")\n",
    "plt.title(\"Correlation heatmap (imshow)\")\n",
    "plt.xticks(range(len(corr.columns)), corr.columns, rotation=90, fontsize=8)\n",
    "plt.yticks(range(len(corr.index)), corr.index, fontsize=8)\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) EDA: Outliers minh hoạ \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution_count": null,
    "outputs": []
   },
   "source": [
    "plt.figure(figsize=(18, 6))\n",
    "df[feature_cols].boxplot(rot=90)\n",
    "plt.title(\"Boxplot BEFORE outlier handling\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Preprocessing leak-free: Imputer + IQR clipping + Scaler + OneHot\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution_count": null,
    "outputs": []
   },
   "source": [
    "class IQRClipper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Clip outliers theo IQR (không drop mẫu), leak-free khi nằm trong Pipeline.\"\"\"\n",
    "    def __init__(self, factor=1.5):\n",
    "        self.factor = factor\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        self.q1_ = np.nanpercentile(X, 25, axis=0)\n",
    "        self.q3_ = np.nanpercentile(X, 75, axis=0)\n",
    "        self.iqr_ = self.q3_ - self.q1_\n",
    "        self.lower_ = self.q1_ - self.factor * self.iqr_\n",
    "        self.upper_ = self.q3_ + self.factor * self.iqr_\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        return np.clip(X, self.lower_, self.upper_)\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        if input_features is None:\n",
    "            return None\n",
    "        return np.array(input_features, dtype=object)\n",
    "\n",
    "\n",
    "def make_preprocess(X: pd.DataFrame):\n",
    "    numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "    scaler = StandardScaler() if SCALER_MODE == \"standard\" else MinMaxScaler()\n",
    "\n",
    "    num_pipe = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"iqr\", IQRClipper(factor=IQR_FACTOR)),\n",
    "        (\"scaler\", scaler),\n",
    "    ])\n",
    "\n",
    "    cat_pipe = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\")),\n",
    "    ])\n",
    "\n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", num_pipe, numeric_features),\n",
    "            (\"cat\", cat_pipe, categorical_features),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "    return preprocess\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) 4 mô hình ML (LogReg, DecisionTree, LGBM, XGBoost)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution_count": null,
    "outputs": []
   },
   "source": [
    "def build_models(preprocess):\n",
    "    models = {}\n",
    "\n",
    "    models[\"LogReg\"] = Pipeline([\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\", random_state=RANDOM_STATE))\n",
    "    ])\n",
    "\n",
    "    models[\"DecisionTree\"] = Pipeline([\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"clf\", DecisionTreeClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE))\n",
    "    ])\n",
    "\n",
    "    from lightgbm import LGBMClassifier\n",
    "    models[\"LGBM\"] = Pipeline([\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"clf\", LGBMClassifier(\n",
    "            n_estimators=400, learning_rate=0.05,\n",
    "            random_state=RANDOM_STATE,\n",
    "            is_unbalance=True\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    from xgboost import XGBClassifier\n",
    "    models[\"XGBoost\"] = Pipeline([\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"clf\", XGBClassifier(\n",
    "            n_estimators=400, learning_rate=0.05, max_depth=5,\n",
    "            subsample=0.9, colsample_bytree=0.9,\n",
    "            eval_metric=\"logloss\",\n",
    "            random_state=RANDOM_STATE\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) Hàm đánh giá chung: Acc/Prec/Rec/F1 + Confusion Matrix + ROC-AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution_count": null,
    "outputs": []
   },
   "source": [
    "def get_scores_for_roc(model, X_test):\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        return model.predict_proba(X_test)[:, 1]\n",
    "    if hasattr(model, \"decision_function\"):\n",
    "        s = model.decision_function(X_test)\n",
    "        return (s - s.min()) / (s.max() - s.min() + 1e-9)\n",
    "    return model.predict(X_test)\n",
    "\n",
    "def plot_confusion(cm, title):\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, aspect=\"auto\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "    for (i, j), v in np.ndenumerate(cm):\n",
    "        plt.text(j, i, str(v), ha=\"center\", va=\"center\")\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc(fpr, tpr, auc_score, title):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0, 1], [0, 1])\n",
    "    plt.title(f\"{title} (AUC={auc_score:.4f})\")\n",
    "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_one(name, model, X_train, X_test, y_train, y_test, plot=True):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "    scores = get_scores_for_roc(model, X_test)\n",
    "    fpr, tpr, _ = roc_curve(y_test, scores)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "\n",
    "    if plot:\n",
    "        print(f\"\\n=== {name} ===\")\n",
    "        print(f\"Accuracy : {acc:.4f}\")\n",
    "        print(f\"Precision: {prec:.4f}\")\n",
    "        print(f\"Recall   : {rec:.4f}\")\n",
    "        print(f\"F1-score : {f1:.4f}\")\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plot_confusion(cm, f\"Confusion Matrix - {name}\")\n",
    "        plot_roc(fpr, tpr, auc_score, f\"ROC Curve - {name}\")\n",
    "\n",
    "    return {\"model\": name, \"acc\": acc, \"prec\": prec, \"rec\": rec, \"f1\": f1, \"auc\": auc_score}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12) Chạy theo nhiều tỉ lệ train/test (0.1, 0.2, 0.3) + bảng so sánh\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution_count": null,
    "outputs": []
   },
   "source": [
    "y = df[\"label\"]\n",
    "X = df.drop(columns=[\"quality\", \"label\"]).copy()\n",
    "\n",
    "preprocess = make_preprocess(X)\n",
    "models = build_models(preprocess)\n",
    "\n",
    "rows = []\n",
    "for ts in TEST_SIZES:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=ts, stratify=y, random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    print(f\"\\n\\n==================== test_size={ts} ====================\")\n",
    "    for mname, model in models.items():\n",
    "        r = evaluate_one(f\"{mname}_ts{ts}\", model, X_train, X_test, y_train, y_test, plot=True)\n",
    "        r[\"test_size\"] = ts\n",
    "        r[\"base_model\"] = mname\n",
    "        rows.append(r)\n",
    "\n",
    "results_df = pd.DataFrame(rows).sort_values([\"test_size\",\"auc\"], ascending=[True,False])\n",
    "display(results_df)\n",
    "\n",
    "best_each = results_df.sort_values(\"auc\", ascending=False).groupby(\"test_size\").head(1)\n",
    "print(\"Best per split (by AUC):\")\n",
    "display(best_each)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13) Feature importance (LGBM/XGBoost)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution_count": null,
    "outputs": []
   },
   "source": [
    "def get_feature_names(preprocess, X_train):\n",
    "    num_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    cat_features = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "    names = []\n",
    "    names.extend(num_features)\n",
    "    if len(cat_features) > 0:\n",
    "        ohe = preprocess.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "        names.extend(ohe.get_feature_names_out(cat_features).tolist())\n",
    "    return np.array(names, dtype=object)\n",
    "\n",
    "def plot_importance(pipe, X_train, title, topk=15):\n",
    "    preprocess = pipe.named_steps[\"preprocess\"]\n",
    "    clf = pipe.named_steps[\"clf\"]\n",
    "    feat_names = get_feature_names(preprocess, X_train)\n",
    "\n",
    "    imp = getattr(clf, \"feature_importances_\", None)\n",
    "    if imp is None:\n",
    "        print(\"No feature_importances_\")\n",
    "        return\n",
    "\n",
    "    idx = np.argsort(imp)[::-1][:topk]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feat_names[idx][::-1], imp[idx][::-1])\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "ts = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=ts, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "models[\"LGBM\"].fit(X_train, y_train)\n",
    "plot_importance(models[\"LGBM\"], X_train, \"LGBM Feature Importance (Top 15)\")\n",
    "\n",
    "models[\"XGBoost\"].fit(X_train, y_train)\n",
    "plot_importance(models[\"XGBoost\"], X_train, \"XGBoost Feature Importance (Top 15)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14) Outliers: Boxplot AFTER IQR clipping (minh hoạ)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution_count": null,
    "outputs": []
   },
   "source": [
    "iqr = IQRClipper(factor=IQR_FACTOR)\n",
    "X_num = df[feature_cols].to_numpy(dtype=float)\n",
    "X_clip = iqr.fit_transform(X_num)\n",
    "df_clip = pd.DataFrame(X_clip, columns=feature_cols)\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "df_clip.boxplot(rot=90)\n",
    "plt.title(\"Boxplot AFTER IQR clipping (illustration)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Ghi chú: IQR clipping giảm ảnh hưởng outliers, KHÔNG loại bỏ mẫu.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIONAL 1: So sánh Red vs White (train riêng)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution_count": null,
    "outputs": []
   },
   "source": [
    "def holdout_compare(df_sub, test_size=0.2, drop_wine_type=True):\n",
    "    y_sub = (df_sub[\"quality\"] >= LABEL_THRESHOLD).astype(int)\n",
    "    X_sub = df_sub.drop(columns=[\"quality\"], errors=\"ignore\").copy()\n",
    "    if drop_wine_type:\n",
    "        X_sub = X_sub.drop(columns=[\"wine_type\"], errors=\"ignore\")\n",
    "\n",
    "    preprocess = make_preprocess(X_sub)\n",
    "    models_sub = build_models(preprocess)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_sub, y_sub, test_size=test_size, stratify=y_sub, random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    out = []\n",
    "    for mname, model in models_sub.items():\n",
    "        r = evaluate_one(mname, model, X_train, X_test, y_train, y_test, plot=False)\n",
    "        r[\"test_size\"] = test_size\n",
    "        out.append(r)\n",
    "    return pd.DataFrame(out).sort_values(\"auc\", ascending=False)\n",
    "\n",
    "red_only = df[df[\"wine_type\"]==\"red\"].copy()\n",
    "white_only = df[df[\"wine_type\"]==\"white\"].copy()\n",
    "\n",
    "red_res = holdout_compare(red_only, test_size=0.2)\n",
    "white_res = holdout_compare(white_only, test_size=0.2)\n",
    "\n",
    "print(\"RED:\")\n",
    "display(red_res)\n",
    "print(\"WHITE:\")\n",
    "display(white_res)\n",
    "\n",
    "red_res[\"wine_type\"]=\"red\"\n",
    "white_res[\"wine_type\"]=\"white\"\n",
    "display(pd.concat([red_res, white_res], ignore_index=True).sort_values([\"wine_type\",\"auc\"], ascending=[True,False]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIONAL 2: Regression dự đoán quality (RMSE/MAE/R2)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution_count": null,
    "outputs": []
   },
   "source": [
    "def regression_run(df_all, test_size=0.2):\n",
    "    y_reg = df_all[\"quality\"].astype(float)\n",
    "    X_reg = df_all.drop(columns=[\"quality\",\"label\"], errors=\"ignore\").copy()\n",
    "\n",
    "    preprocess = make_preprocess(X_reg)\n",
    "    reg = Pipeline([\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"reg\", RandomForestRegressor(n_estimators=400, random_state=RANDOM_STATE, n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_reg, y_reg, test_size=test_size, random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    reg.fit(X_train, y_train)\n",
    "    pred = reg.predict(X_test)\n",
    "\n",
    "    rmse = mean_squared_error(y_test, pred) ** 0.5\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    r2 = r2_score(y_test, pred)\n",
    "    return {\"test_size\": test_size, \"rmse\": rmse, \"mae\": mae, \"r2\": r2}\n",
    "\n",
    "reg_df = pd.DataFrame([regression_run(df, ts) for ts in TEST_SIZES])\n",
    "display(reg_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIONAL 3: Cross-Validation ROC-AUC (mean±std)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution_count": null,
    "outputs": []
   },
   "source": [
    "def cv_auc_models(df_all, n_splits=5):\n",
    "    y_cv = (df_all[\"quality\"] >= LABEL_THRESHOLD).astype(int)\n",
    "    X_cv = df_all.drop(columns=[\"quality\",\"label\"], errors=\"ignore\").copy()\n",
    "\n",
    "    preprocess = make_preprocess(X_cv)\n",
    "    models_cv = build_models(preprocess)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "    rows = []\n",
    "    for mname, pipe in models_cv.items():\n",
    "        scores = cross_val_score(pipe, X_cv, y_cv, scoring=\"roc_auc\", cv=skf, n_jobs=-1)\n",
    "        rows.append({\n",
    "            \"model\": mname,\n",
    "            \"folds\": n_splits,\n",
    "            \"mean_auc\": scores.mean(),\n",
    "            \"std_auc\": scores.std(),\n",
    "            \"min_auc\": scores.min(),\n",
    "            \"max_auc\": scores.max()\n",
    "        })\n",
    "    return pd.DataFrame(rows).sort_values(\"mean_auc\", ascending=False)\n",
    "\n",
    "cv_df = cv_auc_models(df, n_splits=CV_FOLDS)\n",
    "display(cv_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIONAL 4: Hyperparameter tuning (RandomizedSearchCV) cho LGBM\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution_count": null,
    "outputs": []
   },
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "y_tune = (df[\"quality\"] >= LABEL_THRESHOLD).astype(int)\n",
    "X_tune = df.drop(columns=[\"quality\",\"label\"], errors=\"ignore\").copy()\n",
    "\n",
    "preprocess = make_preprocess(X_tune)\n",
    "\n",
    "pipe_lgbm = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"clf\", LGBMClassifier(random_state=RANDOM_STATE, is_unbalance=True))\n",
    "])\n",
    "\n",
    "param_dist = {\n",
    "    \"clf__n_estimators\": [200, 400, 800],\n",
    "    \"clf__learning_rate\": [0.03, 0.05, 0.1],\n",
    "    \"clf__max_depth\": [-1, 4, 6, 8],\n",
    "    \"clf__num_leaves\": [15, 31, 63, 127],\n",
    "    \"clf__subsample\": [0.7, 0.85, 1.0],\n",
    "    \"clf__colsample_bytree\": [0.7, 0.85, 1.0],\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    pipe_lgbm,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=skf,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rs.fit(X_tune, y_tune)\n",
    "print(\"Best AUC:\", rs.best_score_)\n",
    "print(\"Best params:\", rs.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kết luận & hướng phát triển\n",
    "\n",
    "- Thường **LGBM/XGBoost** đạt AUC/F1 tốt hơn nhờ boosting học quan hệ phi tuyến.\n",
    "- Logistic Regression là baseline dễ giải thích nhưng hạn chế.\n",
    "- IQR clipping giúp giảm tác động outliers mà **không loại bỏ mẫu**.\n",
    "\n",
    "## Hướng phát triển\n",
    "- Tuning + CV mean±std sâu hơn, thử SHAP để giải thích.\n",
    "- Regression nâng cao với LGBMRegressor/XGBRegressor.\n",
    "- So sánh sâu red vs white.\n",
    "- Triển khai demo dự đoán.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}